{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da37d8d8",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886f34aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import time\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "sys.path.insert(0, 'tools/')\n",
    "\n",
    "from tools import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ff1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks_v1 import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc5410",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85969754",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train = pd.read_csv('dades/processed/training_data.csv', index_col='index')\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = X_train.ctx0.copy()\n",
    "\n",
    "X_val = pd.read_csv('dades/processed/validation_data.csv', index_col='index')\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_val = X_val.ctx0.copy()\n",
    "\n",
    "# X_test = pd.read_csv('dades/processed/testing_data.csv', index_col='index')\n",
    "# X_test = X_test.reset_index(drop=True)\n",
    "# y_test = X_test.ctx0.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451bda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_y_train = ((y_train.copy()*100)/5).round().astype(int)\n",
    "cat_y_val = ((y_val.copy()*100)/5).round().astype(int)\n",
    "# cat_y_test = ((y_test.copy()*100)/5).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fecac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = X_train.year.unique().tolist()\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = X_train.month.unique().tolist()\n",
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_y_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9dfc01",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241df18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "correlations = np.abs(\n",
    "    X_train.loc[X_train.year.isin([2022]),\n",
    "        [\n",
    "            'station_id', 'year', 'month', 'dayofweek',\n",
    "            'day', 'dayofyear', 'hour','capacity', \n",
    "            'ctx0', 'ctx1', 'ctx2', 'ctx3', 'ctx4',\n",
    "            'festius', 'festius_sun', 'festius_sun_sat', \n",
    "            'weekend'\n",
    "        ]\n",
    "    ].corr(method='pearson').ctx0\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# num_docks_available                     0.880782\n",
    "# timestamp                               0.024289\n",
    "# num_bikes_available_types.ebike        -0.393887\n",
    "# num_bikes_available_types.mechanical   -0.755995\n",
    "# num_bikes_available                    -0.865541\n",
    "# is_returning                            0.006442\n",
    "# is_renting                              0.006442\n",
    "# status                                  0.006277\n",
    "\n",
    "correlations.to_dict()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75f88973",
   "metadata": {},
   "source": [
    "columns_meteo = correlations.index[[('VALOR' in i)&('X8' in i) for i in correlations.index]].to_list()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70f8aa7d",
   "metadata": {},
   "source": [
    "correlations.index[[('VALOR' not in i) for i in correlations.index]].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a63fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_meteo = ['VALOR_TN_X4','VALOR_TM_X4', 'VALOR_TX_X4', 'VALOR_PPT_X4']\n",
    "\n",
    "class Config:\n",
    "    num_attribs0 = ['capacity', 'ctx1', 'ctx2', 'ctx3', 'ctx4'] + columns_meteo\n",
    "    cat_attribs0 = ['dayofyear', 'hour', 'month', 'dayofweek', ]\n",
    "#     cat_attribs1 = [station_id]\n",
    "    gen_attribs0 = ['festius_sun', 'weekend']\n",
    "    target_col = ['ctx0']\n",
    "    \n",
    "    epochs=50\n",
    "    batch_size=128\n",
    "    seed=42\n",
    "    lr=1e-4\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=Config()\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc365d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_preprocessor(config):\n",
    "    num_attribs0 = config.num_attribs0\n",
    "    cat_attribs0 = config.cat_attribs0\n",
    "#     cat_attribs1 = config.cat_attribs1\n",
    "    gen_attribs0 = config.gen_attribs0\n",
    "\n",
    "    num_transformer0 = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        ('std_scaler', (StandardScaler())),\n",
    "    ])\n",
    "\n",
    "    categorical_transformer0 = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\",fill_value=0)),\n",
    "        ('ordinal_encoder', (OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan))),\n",
    "    ])\n",
    "    \n",
    "#     categorical_transformer1 = Pipeline(steps=[\n",
    "#         (\"imputer\", SimpleImputer(strategy=\"constant\",fill_value=0)),\n",
    "#         ('one_hot_encoder', (OneHotEncoder(handle_unknown='ignore'))),\n",
    "#     ])\n",
    "    \n",
    "    generic_transformer0 = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\",fill_value=0)),\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num0\", num_transformer0, num_attribs0),\n",
    "            (\"gen1\", generic_transformer0, gen_attribs0),\n",
    "            (\"cat0\", categorical_transformer0, cat_attribs0),\n",
    "#             (\"cat1\", categorical_transformer1, cat_attribs1),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d3d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "full_pipeline = build_preprocessor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "full_pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pipeline(pipline, X, y, args=None, show=True):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    X_prepared = full_pipeline.transform(X)\n",
    "    \n",
    "    if show:\n",
    "        print(\"X\", X.shape, \n",
    "              \"X_prepared:\", X_prepared.shape,\n",
    "              \"y: \", y.shape\n",
    "             )\n",
    "        \n",
    "    if args:\n",
    "        return X_prepared, y, *args\n",
    "    else:\n",
    "        return X_prepared, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f59594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_splits(\n",
    "    pipeline,\n",
    "    data_train,\n",
    "    data_val,\n",
    "#     data_test,\n",
    "    years, \n",
    "    months, \n",
    "    show=True\n",
    "):\n",
    "    if show:\n",
    "        print(\"train\")\n",
    "    \n",
    "    train_cond = (data_train[0].year.isin(years) & data_train[0].month.isin(months))\n",
    "    Xtr, ytr = apply_pipeline(\n",
    "        pipeline,\n",
    "        data_train[0][train_cond], \n",
    "        data_train[1][train_cond],\n",
    "        show=show\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        print(\"val\")\n",
    "    \n",
    "    val_cond = (data_val[0].year.isin(years) & data_val[0].month.isin(months))\n",
    "    Xva, yva = apply_pipeline(\n",
    "        pipeline, \n",
    "        data_val[0][val_cond], \n",
    "        data_val[1][val_cond],\n",
    "        show=show\n",
    "    )\n",
    "\n",
    "#     if show:\n",
    "#         print(\"test\")\n",
    "    \n",
    "#     test_cond = (data_test[0].year.isin([2023]) & data_test[0].month.isin([3]))\n",
    "#     Xte, yte = apply_pipeline(\n",
    "#         pipeline, \n",
    "#         data_test[0][test_cond],\n",
    "#         data_test[1][test_cond],\n",
    "#         show=show\n",
    "#     )\n",
    "    \n",
    "    return Xtr, ytr, Xva, yva #, Xte, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c976b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[months.remove(x) for x in [6,7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dda07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years, months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f530aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take data of 2022 \n",
    "\n",
    "X_train, cat_y_train, X_val, cat_y_val = prepare_splits(\n",
    "    full_pipeline,\n",
    "    (X_train, cat_y_train),\n",
    "    (X_val, cat_y_val),\n",
    "#     (X_test, cat_y_test),\n",
    "    [2022], months, True)\n",
    "\n",
    "# X_test, cat_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60023b9",
   "metadata": {},
   "source": [
    "# Needed for NN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a928e27d",
   "metadata": {},
   "source": [
    "%%time \n",
    "\n",
    "X_train = X_train.toarray()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ddb14f8",
   "metadata": {},
   "source": [
    "%%time \n",
    "\n",
    "X_val = X_val.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a4826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# X_test = X_test.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e82213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f1ba6",
   "metadata": {},
   "source": [
    "# Predicción______________________________\n",
    "\n",
    "a) Regresión lineal: relación lineal entre las variables de entrada y la variable de salida. \n",
    "\n",
    "b) Regresión Redes Neuronales (RNN -redes neuronales recurrentes-): pueden capturar relaciones no lineales entre las variables de entrada y salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93dc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fde246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear previous session\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02550e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import logging\n",
    "import sys\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5407b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# Configuring a session\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=3,\n",
    "    inter_op_parallelism_threads=3\n",
    ")\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks_v1 import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5610486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate the input shape\n",
    "input_shape = X_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(cat_y_train.unique())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc824bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    y = K.cast(y_true, K.np.float32)\n",
    "    y_hat = K.cast(y_pred, K.np.float32)\n",
    "    return K.sqrt(K.mean(K.square(y_hat - y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(\n",
    "        shape=(input_shape,)\n",
    "    ),\n",
    "    keras.layers.Dense(input_shape//0.15, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(input_shape//0.20, activation='relu'),\n",
    "    keras.layers.Dense(input_shape//0.50, activation='relu'),\n",
    "    keras.layers.Dense(len(classes), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9284dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard=TensorBoard(log_dir=\"Model_log\")\n",
    "# define a call back\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"./checkpoints/softmax.h5\", \n",
    "    verbose=2, \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10, \n",
    "    verbose=2, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Set a learning rate annealer - to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function.\n",
    "# The LR is decreased dynamically when the score is not improved. This keeps the advantage of the fast computation time with a high LR at the start.\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',  # Track the score on the validation set\n",
    "    patience=5,  # Number of epochs in which no improvement is seen.\n",
    "    verbose=2,\n",
    "    factor=0.8,  # Factor by which the LR is multiplied.\n",
    "    min_lr=0.0000001  # Don't go below this value for LR.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e19935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb72103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "keras.utils.plot_model(model, \"softmax.png\", show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556984b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, cat_y_train, \n",
    "    batch_size=config.batch_size,\n",
    "    epochs=config.epochs, \n",
    "    validation_data=(X_val, cat_y_val), \n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, learning_rate_reduction]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30452fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde96d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea2cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de7c283b",
   "metadata": {},
   "source": [
    "## Generate Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.read_csv('dades/processed/kaggle_sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f468dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8268990",
   "metadata": {},
   "source": [
    "# apply pipeline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38dac3bd",
   "metadata": {},
   "source": [
    "full_pipeline = build_preprocessor(config)\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_val_prepared1 = full_pipeline.transform(X_val1)\n",
    "X_val_prepared2 = full_pipeline.transform(X_val2)\n",
    "X_test_prepared = full_pipeline.transform(sample_data)\n",
    "\n",
    "print(\"x_train_prepared:\",X_train_prepared.shape,\"y_train: \",y_train.shape)\n",
    "print(\"x_test_prepared:\",X_val_prepared1.shape,\"y_test: \",y_val1.shape)\n",
    "print(\"x_test_prepared:\",X_val_prepared2.shape,\"y_test: \",y_val2.shape)\n",
    "print(\"x_test_prepared:\",X_test_prepared.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7be9046e",
   "metadata": {},
   "source": [
    "%%time \n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "cross_val_evaluation(lin_reg,X_train_prepared, y_train,'Linear Regression')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5ceee46",
   "metadata": {},
   "source": [
    "lin_reg.fit(X_train_prepared,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27c93027",
   "metadata": {},
   "source": [
    "test_model(lin_reg, X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55f662bd",
   "metadata": {},
   "source": [
    "test_model(lin_reg, X_val_prepared1, y_val1, X_val_prepared2, y_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7dfe9",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a639da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepared = full_pipeline.transform(sample_data)\n",
    "\n",
    "print(\"x_train_prepared:\",X_train_prepared.shape,\"y_train: \",y_train.shape)\n",
    "print(\"x_test_prepared:\",X_val_prepared1.shape,\"y_test: \",y_val1.shape)\n",
    "print(\"x_test_prepared:\",X_val_prepared2.shape,\"y_test: \",y_val2.shape)\n",
    "print(\"x_test_prepared:\",X_test_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35546150",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lin_reg.predict(X_test_prepared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data['percentage_docks_available'] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22424a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data['percentage_docks_available'].to_csv('predicton_RandomForest.csv', header=True, index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b51da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
